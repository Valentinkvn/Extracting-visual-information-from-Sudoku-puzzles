{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     15,
     54,
     58,
     65
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opencv_python==3.4.2\n",
      "numpy==1.19.2\n",
      "matplotlib==3.3.2\n",
      "PIL==8.0.1\n"
     ]
    }
   ],
   "source": [
    "%config IPCompleter.greedy=True\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import cv2 as cv \n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageEnhance\n",
    "from math import sqrt\n",
    "\n",
    "dirname = os.path.abspath('')\n",
    "\n",
    "class Line:\n",
    "    \"\"\"\n",
    "    Store a line based on the two points.\n",
    "    \"\"\"\n",
    "    def __init__(self, point_1, point_2):\n",
    "        self.point_1 = point_1\n",
    "        self.point_2 = point_2\n",
    "        \n",
    "    \"\"\"\n",
    "    Return the two points that generate the line\n",
    "    \"\"\"\n",
    "    def get_points(self):\n",
    "        return self.point_1, self.point_2\n",
    "        \n",
    "    \"\"\"\n",
    "    Return the scalars that explain the line\n",
    "    Ax + By + C = 0\n",
    "    \"\"\" \n",
    "    def get_line_coeff(self):\n",
    "        A = self.point_1.y - self.point_2.y\n",
    "        B = self.point_2.x - self.point_1.x\n",
    "        C = self.point_1.x * self.point_2.y - self.point_2.x * self.point_1.y\n",
    "        return A,B,C\n",
    "    \n",
    "    \"\"\"\n",
    "    Generate new points to extend an existing line\n",
    "    It is used to extend the lines generated by the Hough transform\n",
    "    over the limits of the Sudoku Grid\n",
    "    \"\"\"\n",
    "    def extend_on_xaxis(self, x):\n",
    "        A,B,C = self.get_line_coeff()\n",
    "        new_y = -(A*x+C)/B\n",
    "        return new_y\n",
    "    \n",
    "    def extend_on_yaxis(self, y):\n",
    "        A,B,C = self.get_line_coeff()\n",
    "        new_x = -(B*y+C)/A\n",
    "        return new_x\n",
    "\n",
    "class Point:\n",
    "    \"\"\"\n",
    "    Class used to describe a point with its coordinates\n",
    "    \"\"\"\n",
    "    def __init__(self, x, y):\n",
    "        self.x = np.int32(np.round(x))\n",
    "        self.y = np.int32(np.round(y))\n",
    "    \n",
    "    def get_point_as_tuple(self):\n",
    "        return (self.x, self.y)\n",
    "    \n",
    "class Patch:\n",
    "    \"\"\"\n",
    "    Store information about each item  in the table. \n",
    "    \"\"\"\n",
    "    def __init__(self, image_patch, x_min, y_min, x_max, y_max, line_idx, column_idx):\n",
    "        self.image_patch = image_patch\n",
    "        self.x_min = x_min\n",
    "        self.y_min = y_min\n",
    "        self.x_max = x_max\n",
    "        self.y_max = y_max\n",
    "        self.line_idx = line_idx\n",
    "        self.column_idx = column_idx\n",
    "        self.has_x: int = 0 # 0 meaning it does not contain an 'X', 1 meaning it contains an 'X'\n",
    "    \n",
    "    def set_x(self, has_x: int):\n",
    "        assert has_x == 0 or has_x == 1 # convention \n",
    "        self.has_x = has_x\n",
    "\n",
    "        \n",
    "def list_of_files(dir_name, extension=\"jpg\"):\n",
    "    \"\"\"\n",
    "    Helper function that returns a list of all \n",
    "    files in a directory with a specific extension\n",
    "    :param dir_name.\n",
    "    :param extension.\n",
    "    :return List of all files with that specific extension\n",
    "    \"\"\"\n",
    "    return [f for f in glob.glob(dir_name+\"*.\" + extension)]\n",
    "\n",
    "\n",
    "def show_image(image, window_name='image'):\n",
    "    \"\"\"\n",
    "    Helper function used to show images\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.title(window_name)\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    \n",
    "    \n",
    "def draw_lines(image, lines: [Line], color: tuple = (0, 0, 255),\n",
    "           return_drawing: bool = False, window_name: str = 'window'):\n",
    "    \"\"\"\n",
    "    Plots the lines into the image.\n",
    "    :param image.\n",
    "    :param lines.\n",
    "    :param color. The color used to draw the lines\n",
    "    :param return_drawing. Use it if you want the drawing to be return instead of displayed.\n",
    "    :return None if return_drawing is False, otherwise returns the drawing.\n",
    "    \"\"\"\n",
    "    drawing = image.copy()\n",
    "    if drawing.ndim == 2:\n",
    "        drawing = cv.cvtColor(drawing, cv.COLOR_GRAY2BGR)\n",
    "    for line in lines: \n",
    "        cv.line(drawing, line.point_1.get_point_as_tuple(), line.point_2.get_point_as_tuple(), color, 2, cv.LINE_AA)\n",
    "\n",
    "    if return_drawing:\n",
    "        return drawing\n",
    "    else:\n",
    "        show_image(drawing, window_name=window_name)\n",
    "\n",
    "\n",
    "def remove_close_lines(lines: [Line], threshold: int, is_vertical: bool):\n",
    "    \"\"\"\n",
    "    It removes the closest lines.\n",
    "    :param lines.\n",
    "    :param threshold. It specify when the lines are too close to each other.\n",
    "    :param is_vertical. Set it to True or False.\n",
    "    :return : The different lines.\n",
    "    \"\"\"\n",
    "    \n",
    "    different_lines = [] \n",
    "    if is_vertical:\n",
    "        lines.sort(key=lambda line: line.point_1.x)\n",
    "    else:\n",
    "        lines.sort(key=lambda line: line.point_1.y)\n",
    "    \n",
    "    #  add the first line\n",
    "    different_lines.append(lines[0])\n",
    "    if is_vertical:\n",
    "        for line_idx in range(1, len(lines)):\n",
    "            if lines[line_idx].point_1.x - different_lines[-1].point_1.x > threshold:\n",
    "                different_lines.append(lines[line_idx])\n",
    "    else:\n",
    "        for line_idx in range(1, len(lines)): \n",
    "            if lines[line_idx].point_1.y - different_lines[-1].point_1.y > threshold:\n",
    "                different_lines.append(lines[line_idx])\n",
    "    return different_lines\n",
    " \n",
    "\n",
    "def slope(x1, y1, x2, y2):\n",
    "    \"\"\"\n",
    "    Calculate the slope of a line by having \n",
    "    the coordinates of two points that describe the line\n",
    "    \"\"\"\n",
    "    m = (y2-y1)/(x2-x1)\n",
    "    return m\n",
    "\n",
    "\n",
    "def get_horizontal_and_vertical_lines_hough(edges, threshold=150, minLineLength=80, maxLineGap=5):\n",
    "    \"\"\"\n",
    "    Returns the horizontal and vertical lines found by Hough transform.\n",
    "    :param edges = the edges of the image.\n",
    "    :threshold = it specifies how many votes need a line to be considered a line.\n",
    "    :minLineLength = minimum length of a line \n",
    "    :maxLineGap \n",
    "    :return (horizontal_lines: List(Line), vertical_lines: List(Line))\n",
    "    \"\"\"\n",
    "    \n",
    "    lines = cv.HoughLinesP(image=edges,rho=1.0,theta=np.pi/180, threshold=threshold,lines=np.array([]), \n",
    "                           minLineLength=minLineLength,maxLineGap=maxLineGap)\n",
    "    lines = np.array(lines)\n",
    "\n",
    "    vertical_lines: [Line] = []\n",
    "    horizontal_lines: [Line] = [] \n",
    "    \n",
    "    for i in range(0, len(lines)):\n",
    "        # TODO: compute the line coordinate\n",
    "        \n",
    "        m = slope(lines[i][0][0], lines[i][0][1], lines[i][0][2], lines[i][0][3])\n",
    "        \n",
    "        pt1 = [lines[i][0][0], lines[i][0][1]]\n",
    "        pt2 = [lines[i][0][2], lines[i][0][3]]\n",
    "        \n",
    "        line = Line(Point(x=pt1[0], y=pt1[1]), Point(x=pt2[0], y=pt2[1])) \n",
    "        \n",
    "        if -0.5 <= m <= 0.5:\n",
    "            new_y1 = line.extend_on_xaxis(x=0)\n",
    "            new_y2 = line.extend_on_xaxis(x=400)\n",
    "            new_line = Line(Point(x=0, y=new_y1), Point(x=400, y=new_y2)) \n",
    "            \n",
    "            horizontal_lines.append(new_line)\n",
    "        elif -1.5 >= m or 1.5 <= m:\n",
    "            new_x1 = line.extend_on_yaxis(y=0)\n",
    "            new_x2 = line.extend_on_yaxis(y=400)\n",
    "            new_line = Line(Point(x=new_x1, y=0), Point(x=new_x2, y=400)) \n",
    "            \n",
    "            vertical_lines.append(new_line) \n",
    "    \n",
    "    return horizontal_lines, vertical_lines\n",
    "\n",
    "\n",
    "def get_intersect(line1, line2):\n",
    "    \"\"\" \n",
    "    Returns the point of intersection of the lines passing through a2,a1 and b2,b1.\n",
    "    a1: [x, y] a point on the line1\n",
    "    a2: [x, y] another point on the line1\n",
    "    b1: [x, y] a point on the line2\n",
    "    b2: [x, y] another point on the line2\n",
    "    \"\"\"\n",
    "    a1, a2 = line1.get_points()\n",
    "    b1, b2 = line2.get_points()\n",
    "    s = np.vstack([a1.get_point_as_tuple(),a2.get_point_as_tuple()\n",
    "                   ,b1.get_point_as_tuple(),b2.get_point_as_tuple()])        # s for stacked\n",
    "    h = np.hstack((s, np.ones((4, 1)))) # h for homogeneous\n",
    "    l1 = np.cross(h[0], h[1])           # get first line\n",
    "    l2 = np.cross(h[2], h[3])           # get second line\n",
    "    x, y, z = np.cross(l1, l2)          # point of intersection\n",
    "    if z == 0:                          # lines are parallel\n",
    "        return (float('inf'), float('inf'))\n",
    "    return [round(x/z), round(y/z)]\n",
    "\n",
    "\n",
    "class MagicClassifier:\n",
    "    \"\"\"\n",
    "    A very strong classifier that detects if the patch has an 'X' or not.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.threshold = 20\n",
    "    \n",
    "    def classic_classify(self, patch: Patch) -> int:\n",
    "        \"\"\"\n",
    "        Receive a Patch and return 1 if there is an 'X' in the patch and 0 otherwise.\n",
    "        \"\"\" \n",
    "        if np.std(patch.image_patch) < self.threshold:\n",
    "            return 0\n",
    "        else: \n",
    "            return 1\n",
    "\n",
    "def classify_patches_with_magic_classifier(patches: [Patch]) -> None:\n",
    "    \"\"\"\n",
    "    Receive the patches and classify if the patch contains an 'X' or not.\n",
    "    :param patches.\n",
    "    :return None\n",
    "    \"\"\"\n",
    "    magic_classifier = MagicClassifier()\n",
    "    for patch in patches:\n",
    "        patch.set_x(magic_classifier.classic_classify(patch))\n",
    "\n",
    "        \n",
    "def show_patches_which_have_x(patches: [Patch]) -> None:\n",
    "    \"\"\"\n",
    "    This function draws a colored rectangle if the patch has an 'X'. \n",
    "    \"\"\"\n",
    "    image_color = np.zeros((400, 400, 3), np.uint8)\n",
    "    y_min = patches[0].y_min\n",
    "    for patch in patches:\n",
    "        x_min_current = patch.x_min \n",
    "        y_min_current = patch.y_min \n",
    "        x_max_current = patch.x_max \n",
    "        y_max_current = patch.y_max \n",
    "\n",
    "        image_color[y_min_current: y_max_current, x_min_current: x_max_current] = np.dstack((patch.image_patch, patch.image_patch, patch.image_patch))\n",
    "        \n",
    "        if patch.has_x == 1:  \n",
    "            cv.rectangle(image_color, (x_min_current, y_min_current), \n",
    "                         (x_max_current, y_max_current), color=(255, 0, 0), thickness=2)\n",
    "    \n",
    "    #show_image(image_color)\n",
    "    \n",
    "def return_patches(patches: [Patch]):\n",
    "    \"\"\"\n",
    "    Return a 9x9 matrix with 'x' and 'o' that describe \n",
    "    if a patch has an x or not in it.\n",
    "    \"\"\"\n",
    "    results = np.full([81], None)\n",
    "    for i, patch in enumerate(patches):\n",
    "        if patch.has_x == 1:  \n",
    "            results[i] = 'x'\n",
    "        else:\n",
    "            results[i] = 'o'\n",
    "    results = results.reshape(9,9)    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_patches(lines, columns, image, step=8, show_patches = False):\n",
    "    \"\"\"\n",
    "    It cuts out each box from the table defined by the lines and columns.\n",
    "    :param lines. The lines that difine the table.\n",
    "    :param columns. The columns that difine the table.\n",
    "    :param image. The image containing the table.\n",
    "    :param show_patches. Determine if the patches will be drawn on the image or not.\n",
    "    :param step. The number of pixels that represent the padding between the actual\n",
    "                extracted patch and the borders given by the sudoku lines\n",
    "    :return : A list with all boxes in the table.\n",
    "    \"\"\"\n",
    "    \n",
    "    def crop_patch(image_, x_min, y_min, x_max, y_max, crop_points):\n",
    "        \"\"\"\n",
    "        Crops the bounding box represented by the coordinates.\n",
    "        \"\"\"\n",
    "        b_box = image_[y_min: y_max, x_min: x_max].copy()\n",
    "        \n",
    "        mask = np.ones_like(b_box) * 255\n",
    "        \n",
    "        res = cv.bitwise_and(b_box,b_box,mask = mask)\n",
    "\n",
    "        return res\n",
    "    \n",
    "    def draw_patch(image_, patch: Patch, points, color: tuple = (255, 0, 255)):\n",
    "        \"\"\"\n",
    "        Draw the irregular shape corresponding to the patch on the image.\n",
    "        \"\"\"\n",
    "        cv.polylines(image_,[points],True,color)\n",
    "    \n",
    "    if len(image.shape) == 3:\n",
    "        image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "    if show_patches: \n",
    "        image_color = np.dstack((image, image, image))\n",
    "  \n",
    "    lines.sort(key=lambda line: line.point_1.y)\n",
    "    columns.sort(key=lambda column: column.point_1.x)\n",
    "    patches = []\n",
    "    step = step\n",
    "    for line_idx in range(len(lines) - 1):\n",
    "        for col_idx in range(len(columns) - 1):\n",
    "            \n",
    "            # get the 4 points of intersection between two consecutive\n",
    "            # vertical and horizontal lines\n",
    "            p1 = get_intersect(lines[line_idx], columns[col_idx])\n",
    "            p2 = get_intersect(lines[line_idx], columns[col_idx+1])\n",
    "            p3 = get_intersect(lines[line_idx+1], columns[col_idx+1])\n",
    "            p4 = get_intersect(lines[line_idx+1], columns[col_idx])\n",
    "            \n",
    "            points = np.array([p1,p2,p3,p4])\n",
    "            \n",
    "            # define the limits of the irregular shape\n",
    "            x_min = np.min(points[:,0]) + step\n",
    "            x_max = np.max(points[:,0]) - step\n",
    "            \n",
    "            y_min = np.min(points[:,1]) + step\n",
    "            y_max = np.max(points[:,1]) - step\n",
    "            \n",
    "            patch = Patch(image_patch=crop_patch(image,  x_min, y_min, x_max, y_max, points),\n",
    "                          x_min=x_min, y_min=y_min, x_max=x_max, y_max=y_max,\n",
    "                          line_idx=line_idx, column_idx=col_idx)\n",
    "            \n",
    "            if show_patches:\n",
    "                draw_patch(image_color, patch, points)\n",
    "            \n",
    "            patches.append(patch)\n",
    "\n",
    "            \n",
    "    if show_patches:\n",
    "        show_image(image_color, window_name='Determined patches')\n",
    "    return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def change_perspective(img_path, brightness_factor=1.2, \n",
    "                       fx=0.125, fy=0.125):\n",
    "    \"\"\"\n",
    "    Change the perspective of the initial image to a new one with the axis aligned\n",
    "    :param img_path. The path to the image that needs to be warped\n",
    "    :param brightness_factor. An enhancing of the brightness is done in order to remove \n",
    "                            a part of the color noise\n",
    "    :param fx. Define the ratio at which the image will be resized on the X axis\n",
    "    :param fy. Define the ratio at which the image will be resized on the Y axis\n",
    "    :return : The warped image\n",
    "    \"\"\"\n",
    "    # open the image in RGB (specific to PIL open process)\n",
    "    pil_image = Image.open(img_path)\n",
    "\n",
    "    # apply the brightness increasing\n",
    "    enhancer = ImageEnhance.Brightness(pil_image)\n",
    "    factor = brightness_factor\n",
    "    pil_image = enhancer.enhance(factor)\n",
    "\n",
    "    # convert the image from RGB to BGR and resize it\n",
    "    sample_image = cv.cvtColor(np.array(pil_image), cv.COLOR_RGB2BGR)\n",
    "\n",
    "    img_shape = sample_image.shape\n",
    "\n",
    "    sample_image = cv.resize(sample_image,None,fx=fx,fy=fy)\n",
    "\n",
    "    # convert the image to grayscale and apply an adaptive threshold to binarize \n",
    "    # the important features in the images\n",
    "    gray_image = cv.cvtColor(sample_image, cv.COLOR_BGR2GRAY)\n",
    "    blur = cv.medianBlur(gray_image, 3)\n",
    "    edges = cv.adaptiveThreshold(blur,255,cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY_INV,11,3)\n",
    "\n",
    "    # find the contours and take the biggest one as a reference\n",
    "    _, contours, _ = cv.findContours(edges,cv.RETR_TREE,cv.CHAIN_APPROX_SIMPLE)\n",
    "    cnt = sorted(contours, key=cv.contourArea, reverse=True)\n",
    "    biggest_cont = cnt[0]\n",
    "\n",
    "    # create a mask using the biggest contour\n",
    "    mask = np.zeros_like(gray_image)\n",
    "    cv.drawContours(mask,[biggest_cont],0,255,-1)\n",
    "    cv.drawContours(mask,[biggest_cont],0,0,2)\n",
    "    res = cv.bitwise_and(sample_image,sample_image,mask = mask)\n",
    "\n",
    "    # get the rectangle that best describes the biggest contour and \n",
    "    # take the four points of the rectangle\n",
    "    biggest_cont = np.squeeze(biggest_cont, axis=1)\n",
    "    box_corners = []\n",
    "    rot_rect = cv.minAreaRect(biggest_cont)\n",
    "    box = cv.boxPoints(rot_rect)\n",
    "    box = np.int0(box)\n",
    "    for p in box:\n",
    "        box_corners.append([p[0],p[1]])\n",
    "\n",
    "    # check the rotation of the sudoku grid\n",
    "    # it is important to understand the orientation of the sudoku grid\n",
    "    # in order to have a proper perspective warping\n",
    "    if box_corners[1][1] > box_corners[3][1]:\n",
    "        dst = [[350,350],[50,350],[50,50],[350,50]]\n",
    "    else:\n",
    "        dst = [[50,350],[50,50],[350,50],[350,350]]\n",
    "\n",
    "    # calculate the transform matrix needed for the warping process\n",
    "    M = cv.getPerspectiveTransform(np.float32(box_corners), np.float32(dst))\n",
    "\n",
    "    # warp the initial image using the M transform matrix\n",
    "    warped = cv.warpPerspective(res, M, res.shape[:2], flags=cv.INTER_LINEAR)\n",
    "    \n",
    "    return warped, M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def predict_patches(warped, task_no, step=8, hough_thresh=100,\n",
    "                   minLineLength=80, maxLineGap=5, show_results=False):\n",
    "    \"\"\"\n",
    "    Detect the lines corresponding to the sudoku grid and based on them\n",
    "    draw and determine the important features of the patches\n",
    "    :param warped. The warped image as the input\n",
    "    :param task_no. 1 or 2 based on the task that the function solves\n",
    "    :param step. Parameter used for the get_patches function (see get_patches)\n",
    "    :param hough_thresh. Parameter used for get_horizontal_and_vertical_lines_hough function \n",
    "    :param minLineLength. Parameter used for get_horizontal_and_vertical_lines_hough function \n",
    "    :param maxLineGap. Parameter used for get_horizontal_and_vertical_lines_hough function \n",
    "    :param show_results. Print the images\n",
    "    :return : The matrix of the presence of features in patches, and for task 2, also return the patches\n",
    "    \"\"\"\n",
    "    \n",
    "    edges = cv.Canny(warped,90,255)\n",
    "    \n",
    "    if show_results:\n",
    "        show_image(edges, \"Canny edges detection\")\n",
    "        \n",
    "    if task_no == 1:\n",
    "        kernel = np.ones((2,2),np.uint8)\n",
    "        edges = cv.dilate(edges,kernel)\n",
    "        \n",
    "    if task_no == 2:\n",
    "        kernel = np.ones((3,3),np.uint8)\n",
    "        edges = cv.dilate(edges,kernel)\n",
    "\n",
    "    if show_results:\n",
    "        show_image(edges, \"Canny after morphological dilation procedure\")\n",
    "    \n",
    "    # get the horizontal and vertical lines based on hough detection\n",
    "    horizontal_lines, vertical_lines = get_horizontal_and_vertical_lines_hough(edges,hough_thresh,minLineLength,maxLineGap)\n",
    "\n",
    "    if show_results:\n",
    "        draw_lines(warped, horizontal_lines, window_name='Horizontal lines')\n",
    "        draw_lines(warped, vertical_lines, window_name='Vertical lines')\n",
    "\n",
    "    distinct_horizontal_lines = remove_close_lines(horizontal_lines, threshold = 20, is_vertical = False)\n",
    "    distinct_vertical_lines = remove_close_lines(vertical_lines, threshold = 20, is_vertical = True)\n",
    "\n",
    "    if show_results:\n",
    "        draw_lines(warped, distinct_vertical_lines, window_name='Vertical lines after removing')\n",
    "        draw_lines(warped, distinct_horizontal_lines, window_name='Horizontal lines after removing')\n",
    "\n",
    "    patches = get_patches(distinct_horizontal_lines, distinct_vertical_lines, warped, step,\n",
    "                                  show_patches=False)\n",
    "\n",
    "    classify_patches_with_magic_classifier(patches) \n",
    "\n",
    "    if task_no == 1:\n",
    "        show_patches_which_have_x(patches)\n",
    "        return return_patches(patches)\n",
    "    if task_no == 2:\n",
    "        show_patches_which_have_x(patches)\n",
    "        return return_patches(patches), patches  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def evaluate_task1(train_or_test='train'):\n",
    "    \"\"\"\n",
    "    Evaluate task 1 on the 'classic' input set\n",
    "    :param train_or_test. The source of the files. It can be either 'train' or 'test'.\n",
    "            To find the input images, the root folder where the notebook is located is taken\n",
    "            into consideration.\n",
    "    :output. The files with the resulting output will be saved at:\n",
    "            <current_directory>/evaluation/submission_files/classic/\"\n",
    "    \"\"\"\n",
    "    print(\"Evaluate task 1\")\n",
    "    \n",
    "    # get the path to the images and define all the other necessary paths\n",
    "    imgs_path = list_of_files(dirname + \"/\" + train_or_test + \"/classic/\")\n",
    "    predictions_path_root = \"/evaluation/submission_files/\"\n",
    "    predictions_path = dirname + predictions_path_root + \"classic/\"\n",
    "\n",
    "    for i in range(len(imgs_path)):\n",
    "        print(\"Image \" + str(i+1) + \" from \" + str(len(imgs_path)) + \" for task 1\")\n",
    "        warped, M = change_perspective(imgs_path[i])\n",
    "        result = predict_patches(warped, task_no=1, show_results=False)\n",
    "        img_no = imgs_path[i].split(\"/\")[-1].split(\".\")[0]\n",
    "        \n",
    "        # save the results, line by line, to *_predicted files\n",
    "        with open(predictions_path + str(img_no) + '_predicted.txt','w') as f:\n",
    "            for j, line in enumerate(result):\n",
    "                line_str = ''.join(line)\n",
    "                if j < 8:\n",
    "                    f.write(line_str + \"\\n\")\n",
    "                else:\n",
    "                    f.write(line_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0,
     17,
     26
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_gabor_filters(theta_list, lambda_list) -> list:\n",
    "    \"\"\"\n",
    "    Build Gabor filters with the window size of 55 pixels and theta and lambda received in the paramters.\n",
    "    :param theta_list. The list with the theta parameters.\n",
    "    :param lambda_list. The list the lambda paramters.\n",
    "    :return. list of Gabor filters.\n",
    "    \"\"\"\n",
    "    filters = []\n",
    "    ksize = 55\n",
    "    \n",
    "    for lambda_ in lambda_list:   \n",
    "        for theta in theta_list:    \n",
    "            kern = cv.getGaborKernel((ksize, ksize), 4, theta, lambda_, 0.5, 0, ktype=cv.CV_32F)\n",
    "            kern /= 1.5 * kern.sum()\n",
    "            filters.append(kern)            \n",
    "    return filters\n",
    "\n",
    "def apply_filters(img, filter):\n",
    "    \"\"\"\n",
    "    :param img - the image on which we apply the filters.\n",
    "    :param filter - a list with filters.\n",
    "    :return. The results of applying the filters on the image.\n",
    "    \"\"\" \n",
    "    response = np.abs(cv.filter2D(img, cv.CV_32F, filter))\n",
    "    return (255*(response - np.min(response))/np.ptp(response)).astype(int) \n",
    "        \n",
    "def dfs(horizontal, vertical, ids, current_i, current_j, current_id):\n",
    "    \"\"\"\n",
    "    A depth first search to determine the patches that correspond to \n",
    "    the same jigsaw sudoku region\n",
    "    :param horizontal - a 8x8 matrix that contains all the horizontal thick lines in the irregular sudoku grid\n",
    "    :param vertical - a 8x8 matrix that contains all the vertical thick lines in the irregular sudoku grid\n",
    "    :param ids - a 9x9 matrix that contains the ids of each of the patches from the sudoku grid\n",
    "    :param current_i - the current i position\n",
    "    :param current_j - the current j position\n",
    "    :param current_id - the current id of the i,j position\n",
    "    :return. The 9x9 matrix that contains all the ids \n",
    "    \"\"\" \n",
    "    if ids[current_i,current_j] != 0:\n",
    "        return\n",
    "\n",
    "    ids[current_i,current_j] = current_id\n",
    "\n",
    "    neigh = []\n",
    "\n",
    "    if current_i > 0:\n",
    "        # north\n",
    "        if horizontal[current_i-1,current_j] == 0:\n",
    "            neigh.append([current_i-1,current_j])\n",
    "\n",
    "    if current_i < 8:\n",
    "        # south\n",
    "        if horizontal[current_i,current_j] == 0:\n",
    "            neigh.append([current_i+1,current_j])\n",
    "\n",
    "    if current_j > 0:\n",
    "        # west\n",
    "        if vertical[current_i,current_j-1] == 0:\n",
    "            neigh.append([current_i,current_j-1])\n",
    "\n",
    "    if current_j < 8:\n",
    "        # east\n",
    "        if vertical[current_i,current_j] == 0:\n",
    "            neigh.append([current_i,current_j+1])\n",
    "\n",
    "    for next_i, next_j in neigh:\n",
    "        dfs(horizontal, vertical, ids, next_i, next_j, current_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def evaluate_task2(train_or_test='train'):\n",
    "    \"\"\"\n",
    "    Evaluate task 2 on the 'jigsaw' input set\n",
    "    :param train_or_test. The source of the files. It can be either 'train' or 'test'.\n",
    "            To find the input images, the root folder where the notebook is located is taken\n",
    "            into consideration.\n",
    "    :output. The files with the resulting output will be saved at:\n",
    "            <current_directory>/evaluation/submission_files/jigsaw/\"\n",
    "    \"\"\"\n",
    "    print(\"Evaluate task 2\")\n",
    "    imgs_path = list_of_files(dirname+\"/\" + train_or_test + \"/jigsaw/\")\n",
    "    \n",
    "    predictions_path_root = \"/evaluation/submission_files/\"\n",
    "\n",
    "    predictions_path = dirname + predictions_path_root + \"jigsaw/\"\n",
    "\n",
    "    # define the theta list as 0 and pi/2 because we want to determine the horizontal and vertical thick lines\n",
    "    theta_list = [0, np.pi/2]\n",
    "    # the lambda parameter list was defined as [8,10]\n",
    "    lambda_list = [8, 10]\n",
    "    gabor_filters = build_gabor_filters(theta_list=theta_list, lambda_list=lambda_list)\n",
    "\n",
    "    for i in range(len(imgs_path)):\n",
    "        print(\"Image \" + str(i+1) + \" from \" + str(len(imgs_path)) + \" for task 2\")\n",
    "        warped, M = change_perspective(imgs_path[i])\n",
    "        result, patches = predict_patches(warped, task_no=2, show_results=False)\n",
    "        \n",
    "        mask = np.zeros(warped.shape[:2])\n",
    "\n",
    "        # apply the filters over the resulted warped image\n",
    "        warped = cv.cvtColor(warped,cv.COLOR_BGR2GRAY)\n",
    "        for gabor_filter in gabor_filters[2:]:\n",
    "            response = apply_filters(warped, gabor_filter)\n",
    "            mask[response>150] = 255\n",
    "\n",
    "        horizontal_thick_lines = np.zeros(81)\n",
    "        vertical_thick_lines = np.zeros((81))\n",
    "        \n",
    "        # check if the region between two patches (either vertical or horizontal) \n",
    "        # contains any \"white\" points that corresponds to the thick lines\n",
    "        for j in range(len(patches)-1):\n",
    "            # check the horizontal regions between patches\n",
    "            if (j == 0) or ((j+1) % 9 != 0):\n",
    "                y_mean = round((patches[j].y_max+patches[j].y_min)/2)\n",
    "                x_mean = round((patches[j].x_max+patches[j+1].x_min)/2)\n",
    "                line_pts = 0\n",
    "                for k in range(patches[j].x_max, patches[j+1].x_min):\n",
    "                    if mask[y_mean, k] > 0:\n",
    "                        line_pts += 1\n",
    "                # if more than two thick line points were detected, then a thick line is present in that region\n",
    "                if line_pts > 2:\n",
    "                    vertical_thick_lines[j] = 1\n",
    "                    \n",
    "            if (j < len(patches) - 9):\n",
    "                # check the vertical regions between patches\n",
    "                x_mean = round((patches[j].x_max+patches[j].x_min)/2)\n",
    "                y_mean = round((patches[j].y_max+patches[j+9].y_min)/2)\n",
    "                line_pts = 0\n",
    "                for k in range(patches[j].y_max, patches[j+9].y_min):\n",
    "                    if mask[k, x_mean] > 0:\n",
    "                        line_pts += 1\n",
    "                if line_pts > 2:\n",
    "                    horizontal_thick_lines[j] = 1    \n",
    "        \n",
    "        vertical_thick_lines = vertical_thick_lines.reshape(9,9)\n",
    "        horizontal_thick_lines = horizontal_thick_lines.reshape(9,9)\n",
    "        \n",
    "        ids = np.zeros((9,9),dtype=np.int8)\n",
    "        \n",
    "        # apply dfs and determine the id of each of the patches\n",
    "        for j in range(9):\n",
    "            for k in range(9):\n",
    "                if ids[j,k] == 0:\n",
    "                    id = np.max(ids) + 1\n",
    "                    dfs(horizontal_thick_lines,vertical_thick_lines,ids,j,k,id)\n",
    "        \n",
    "        # save the final results\n",
    "        img_no = imgs_path[i].split(\"/\")[-1].split(\".\")[0]\n",
    "        with open(predictions_path + str(img_no) + '_predicted.txt','w') as f:\n",
    "            j = 0\n",
    "            for line_isdigit, line_ids in zip(result,ids):\n",
    "                line_str = \"\"\n",
    "                for isdigit, ids in zip(line_isdigit, line_ids):\n",
    "                    line_str +=  str(int(ids)) + str(isdigit)\n",
    "                \n",
    "                if j < 8:\n",
    "                    f.write(line_str + \"\\n\")\n",
    "                else:\n",
    "                    f.write(line_str)\n",
    "                    \n",
    "                j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0,
     16,
     52
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_matrix_boundary(matrix, bound_no):\n",
    "    \"\"\"\n",
    "    Get the lines that are located at the boundary of the matrix in various directions\n",
    "    :param matrix - 9x9 matrix from which the line is extracted\n",
    "    :param bound_no - the position 0-north/1-east/2-west/3-south\n",
    "    :return. the boundary line\n",
    "    \"\"\" \n",
    "    if bound_no == 0:\n",
    "        return matrix[0,:]\n",
    "    if bound_no == 3:\n",
    "        return matrix[-1,:]\n",
    "    if bound_no == 1:\n",
    "        return matrix[:,-1]\n",
    "    if bound_no == 2:\n",
    "        return matrix[:, 0]\n",
    "\n",
    "def check_rotations(matrixes):\n",
    "    \"\"\"\n",
    "    Match the 3 sudoku positions that define the sudoku cube.\n",
    "    :param matrixes - 3 9x9 matrixes corresponding to each sudoku grid to be matched\n",
    "    :return. i, j, k corresponding to the position of each sudoku after match\n",
    "        i - bottom-left\n",
    "        j - top\n",
    "        k - bottom-right\n",
    "    \"\"\" \n",
    "    first_matrix = matrixes[0,:,:]\n",
    "    second_matrix = matrixes[1,:,:]\n",
    "    third_matrix = matrixes[2,:,:]\n",
    "    \n",
    "    i = 0\n",
    "    j = 0\n",
    "    k = 0\n",
    "    # match the first and second sudokus\n",
    "    for i in range(len(matrixes)):\n",
    "        found = 0\n",
    "        for j in range(len(matrixes)):\n",
    "            if i != j:\n",
    "                first_matrix_match = get_matrix_boundary(matrixes[i], 0)\n",
    "                second_matrix_match = get_matrix_boundary(matrixes[j], 3)\n",
    "                if (first_matrix_match == second_matrix_match).all():\n",
    "                    found = 1\n",
    "                    break\n",
    "        if found == 1:\n",
    "            break\n",
    "    \n",
    "    # find the position of the third sudoku grid\n",
    "    for k in range(3):\n",
    "        if k != i and k != j:\n",
    "            break\n",
    "            \n",
    "    return j,i,k\n",
    "    \n",
    "def warp_on_cube(img, template, position, src_pos, rotation):\n",
    "    \"\"\"\n",
    "    Warp a sudoku grid on the sudoku cube considering the position calculated\n",
    "    previously by matching the digits of each sudoku grid\n",
    "    :param img - the warped image of the sudoku grid\n",
    "    :param template - the cube where the grid will be pasted\n",
    "    :param position - 0,1,2 corresponding to the three positions on the cube\n",
    "    :param src_pos - the source position defined in pixels of the corners of the grid\n",
    "    :param rotation - the rotation of the sudoku grid according to the axis\n",
    "    :return. weighted image of the adding of the grid over the cube template\n",
    "    \"\"\" \n",
    "    dest = []\n",
    "    # statically define the destination points for the warping\n",
    "    if rotation == 0:\n",
    "        if position == 0:\n",
    "            dest = [[295,538], [4,460], [8,157], [296,233]]\n",
    "        if position == 1:\n",
    "            dest = [[560,386], [295,538], [296,233], [560,82]]\n",
    "        if position == 2:\n",
    "            dest = [[296,233], [8,157], [272,2], [560,82]]\n",
    "    else:\n",
    "        if position == 0:\n",
    "            dest = [[4,460], [8,157], [296,233], [295,538]]\n",
    "        if position == 1:\n",
    "            dest = [[295,538], [296,233], [560,82], [560,386]]\n",
    "        if position == 2:\n",
    "            dest = [[8,157], [272,2], [560,82], [296,233]]\n",
    "        \n",
    "    # define a alpha mask that will be applied over the image of the sudoku grid\n",
    "    alpha_mask = np.zeros((img.shape[0],img.shape[1]))\n",
    "    alpha_mask[50:350,50:350] = 255\n",
    "    img = cv.cvtColor(img, cv.COLOR_BGR2BGRA) \n",
    "    img[:,:,3] = alpha_mask\n",
    "    \n",
    "    # get the transform and apply it to the image\n",
    "    M = cv.getPerspectiveTransform(np.float32(src_pos), np.float32(dest))\n",
    "    img = cv.warpPerspective(img, M, img.shape[:2], flags=cv.INTER_LINEAR)\n",
    "    \n",
    "    # add the BGRA warped image of the sudoku grid over the template image\n",
    "    added_image = cv.addWeighted(template,1,img,1,0)\n",
    "        \n",
    "    return added_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     113
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def evaluate_task3(train_or_test='train'):\n",
    "    \"\"\"\n",
    "    Evaluate task 3 on the 'cube' input set\n",
    "    :param train_or_test. The source of the files. It can be either 'train' or 'test'.\n",
    "            To find the input images, the root folder where the notebook is located is taken\n",
    "            into consideration.\n",
    "    :output. The files with the resulting output will be saved at:\n",
    "            <current_directory>/evaluation/submission_files/cube/\"\n",
    "    \"\"\"\n",
    "    print(\"Evaluate task 3\")\n",
    "    imgs_path = list_of_files(dirname + \"/\" + train_or_test + \"/cube/\")\n",
    "    \n",
    "    mean_img = np.load('mean_img_digits.npy')\n",
    "\n",
    "    imgs_path = [path for path in imgs_path if \"result\" not in path and \"template\" not in path]\n",
    "    \n",
    "    predictions_path_root = \"/evaluation/submission_files/\"\n",
    "\n",
    "    predictions_path = dirname + predictions_path_root + \"cube/\"\n",
    "    \n",
    "    # open the template image and transform it to a 4 channel (alpha added) image\n",
    "    template = cv.imread(dirname+\"/train/cube/template.jpg\")\n",
    "    template = cv.cvtColor(template, cv.COLOR_BGR2BGRA)\n",
    "    template[:,:,3] = np.ones((template.shape[:2])) * 255\n",
    "    \n",
    "    for i in range(len(imgs_path)):\n",
    "        print(\"Image \" + str(i+1) + \" from \" + str(len(imgs_path)) + \" for task 3\")\n",
    "        # open the image and apply an adaptiveThreshold method to find the needed features\n",
    "        image = cv.imread(imgs_path[i])\n",
    "        gray_image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "        blur = cv.medianBlur(gray_image, 3)\n",
    "        edges = cv.adaptiveThreshold(blur,255,cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY_INV,11,3)\n",
    "        \n",
    "        # find the 3 biggest contors that correspind to each of the sudoku grids\n",
    "        _, contours, _ = cv.findContours(edges,cv.RETR_TREE,cv.CHAIN_APPROX_SIMPLE)\n",
    "        cnt = sorted(contours, key=cv.contourArea, reverse=True)\n",
    "        biggest_cont = cnt[0:3]\n",
    "        \n",
    "        # calculate the mask for each of the grids regarding their contours\n",
    "        res = []\n",
    "        for big_cont in biggest_cont:\n",
    "            mask = np.zeros_like(gray_image)\n",
    "            cv.drawContours(mask,[big_cont],0,255,-1)\n",
    "            cv.drawContours(mask,[big_cont],0,0,2)\n",
    "            res.append(cv.bitwise_and(image,image,mask = mask))\n",
    "\n",
    "        # get the corners of each of the contours\n",
    "        contour_corners = []\n",
    "        for contour in biggest_cont:\n",
    "            box_corners = []\n",
    "            rot_rect = cv.minAreaRect(contour)\n",
    "            box = cv.boxPoints(rot_rect)\n",
    "            box = np.int0(box)\n",
    "            for p in box:\n",
    "                box_corners.append([p[0],p[1]])\n",
    "            contour_corners.append(box_corners)\n",
    "            \n",
    "        # get the rotation, the warping destination and the warped image of each of the grids\n",
    "        final_dst = []\n",
    "        rotation = []\n",
    "        warped = []\n",
    "        for j, box_corners in enumerate(contour_corners):\n",
    "            if box_corners[1][1] > box_corners[3][1]:\n",
    "                dst = [[350,350],[50,350],[50,50],[350,50]]\n",
    "                rotation.append(0)\n",
    "            else:\n",
    "                dst = [[50,350],[50,50],[350,50],[350,350]]\n",
    "                rotation.append(1)\n",
    "    \n",
    "            final_dst.append(dst)\n",
    "            M = cv.getPerspectiveTransform(np.float32(box_corners), np.float32(dst))\n",
    "\n",
    "            warped_image = cv.warpPerspective(res[j], M, res[j].shape[:2], \n",
    "                                              flags=cv.INTER_LINEAR)[:template.shape[1],:template.shape[0]]\n",
    "                                                                                                  \n",
    "            warped.append(warped_image)\n",
    "            \n",
    "        # using the difference between image and the mean images, find the digit present in the patches\n",
    "        sudoku_digits = np.zeros((3,9,9))\n",
    "        for n, warped_image in enumerate(warped):\n",
    "            # split the sudoku grid in 81 regions that are empirically determined\n",
    "            for j in range(9):\n",
    "                for k in range(9): \n",
    "                    distances = []\n",
    "                    # calculate the patch\n",
    "                    digit = warped_image[round(300/9)*j+54:round(300/9)*(j+1)+50,\n",
    "                                           round(300/9)*k+54:round(300/9)*(k+1)+50]\n",
    "                    digit = cv.cvtColor(digit, cv.COLOR_BGR2GRAY)\n",
    "                    \n",
    "                    # calculate the euclidean distance between our patch and each of the means of the digits\n",
    "                    for m in range(1,10):\n",
    "                        distances.append(np.linalg.norm(digit-mean_img[m]))\n",
    "                    \n",
    "                    # get the digit present in the current patch\n",
    "                    sudoku_digits[n,j,k] = np.argmin(distances) + 1\n",
    "                    \n",
    "        # match the position of each of the grids\n",
    "        idx1, idx2, idx3 = check_rotations(sudoku_digits)\n",
    "    \n",
    "        # warp the sudokus over the cube\n",
    "        t = np.zeros((template.shape), dtype=np.uint8())\n",
    "        t = warp_on_cube(warped[idx1], t, 2, final_dst[0], rotation[0])\n",
    "        t = warp_on_cube(warped[idx2], t, 0, final_dst[1], rotation[1])\n",
    "        t = warp_on_cube(warped[idx3], t, 1, final_dst[2], rotation[2])\n",
    "\n",
    "        # save the results to the corresponding files\n",
    "        img_no = imgs_path[i].split(\"/\")[-1].split(\".\")[0]\n",
    "        with open(predictions_path + str(img_no) + '_predicted.txt','w') as f:\n",
    "            for j, line in enumerate(sudoku_digits[idx1]):\n",
    "                line_str = \"\"\n",
    "                for digit in line:\n",
    "                    line_str += str(int(digit))\n",
    "                if j < 8:\n",
    "                    f.write(line_str + \"\\n\")\n",
    "                else:\n",
    "                    f.write(line_str + \"\\n\\n\")\n",
    "\n",
    "            j = 0\n",
    "            for line1, line2 in zip(sudoku_digits[idx2],sudoku_digits[idx3]):\n",
    "                line_str1 = \"\"\n",
    "                line_str2 = \"\"\n",
    "                line_final = \"\"\n",
    "                for digit1, digit2 in zip(line1, line2):\n",
    "                    line_str1 += str(int(digit1))\n",
    "                    line_str2 += str(int(digit2))\n",
    "                line_final = line_str1 + \" \" + line_str2\n",
    "                \n",
    "                if j < 8:\n",
    "                    f.write(line_final + \"\\n\")\n",
    "                else:\n",
    "                    f.write(line_final)\n",
    "                    \n",
    "                j += 1\n",
    "                \n",
    "        cv.imwrite(predictions_path + str(img_no) + '_result.jpg', t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate task 1\n",
      "Image 1 from 50 for task 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/valentin/miniconda3/envs/virtual-env/lib/python3.7/site-packages/ipykernel_launcher.py:165: RuntimeWarning: divide by zero encountered in int_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 2 from 50 for task 1\n",
      "Image 3 from 50 for task 1\n",
      "Image 4 from 50 for task 1\n",
      "Image 5 from 50 for task 1\n",
      "Image 6 from 50 for task 1\n",
      "Image 7 from 50 for task 1\n",
      "Image 8 from 50 for task 1\n",
      "Image 9 from 50 for task 1\n",
      "Image 10 from 50 for task 1\n",
      "Image 11 from 50 for task 1\n",
      "Image 12 from 50 for task 1\n",
      "Image 13 from 50 for task 1\n",
      "Image 14 from 50 for task 1\n",
      "Image 15 from 50 for task 1\n",
      "Image 16 from 50 for task 1\n",
      "Image 17 from 50 for task 1\n",
      "Image 18 from 50 for task 1\n",
      "Image 19 from 50 for task 1\n",
      "Image 20 from 50 for task 1\n",
      "Image 21 from 50 for task 1\n",
      "Image 22 from 50 for task 1\n",
      "Image 23 from 50 for task 1\n",
      "Image 24 from 50 for task 1\n",
      "Image 25 from 50 for task 1\n",
      "Image 26 from 50 for task 1\n",
      "Image 27 from 50 for task 1\n",
      "Image 28 from 50 for task 1\n",
      "Image 29 from 50 for task 1\n",
      "Image 30 from 50 for task 1\n",
      "Image 31 from 50 for task 1\n",
      "Image 32 from 50 for task 1\n",
      "Image 33 from 50 for task 1\n",
      "Image 34 from 50 for task 1\n",
      "Image 35 from 50 for task 1\n",
      "Image 36 from 50 for task 1\n",
      "Image 37 from 50 for task 1\n",
      "Image 38 from 50 for task 1\n",
      "Image 39 from 50 for task 1\n",
      "Image 40 from 50 for task 1\n",
      "Image 41 from 50 for task 1\n",
      "Image 42 from 50 for task 1\n",
      "Image 43 from 50 for task 1\n",
      "Image 44 from 50 for task 1\n",
      "Image 45 from 50 for task 1\n",
      "Image 46 from 50 for task 1\n",
      "Image 47 from 50 for task 1\n",
      "Image 48 from 50 for task 1\n",
      "Image 49 from 50 for task 1\n",
      "Image 50 from 50 for task 1\n",
      "Evaluate task 2\n",
      "Image 1 from 40 for task 2\n",
      "Image 2 from 40 for task 2\n",
      "Image 3 from 40 for task 2\n",
      "Image 4 from 40 for task 2\n",
      "Image 5 from 40 for task 2\n",
      "Image 6 from 40 for task 2\n",
      "Image 7 from 40 for task 2\n",
      "Image 8 from 40 for task 2\n",
      "Image 9 from 40 for task 2\n",
      "Image 10 from 40 for task 2\n",
      "Image 11 from 40 for task 2\n",
      "Image 12 from 40 for task 2\n",
      "Image 13 from 40 for task 2\n",
      "Image 14 from 40 for task 2\n",
      "Image 15 from 40 for task 2\n",
      "Image 16 from 40 for task 2\n",
      "Image 17 from 40 for task 2\n",
      "Image 18 from 40 for task 2\n",
      "Image 19 from 40 for task 2\n",
      "Image 20 from 40 for task 2\n",
      "Image 21 from 40 for task 2\n",
      "Image 22 from 40 for task 2\n",
      "Image 23 from 40 for task 2\n",
      "Image 24 from 40 for task 2\n",
      "Image 25 from 40 for task 2\n",
      "Image 26 from 40 for task 2\n",
      "Image 27 from 40 for task 2\n",
      "Image 28 from 40 for task 2\n",
      "Image 29 from 40 for task 2\n",
      "Image 30 from 40 for task 2\n",
      "Image 31 from 40 for task 2\n",
      "Image 32 from 40 for task 2\n",
      "Image 33 from 40 for task 2\n",
      "Image 34 from 40 for task 2\n",
      "Image 35 from 40 for task 2\n",
      "Image 36 from 40 for task 2\n",
      "Image 37 from 40 for task 2\n",
      "Image 38 from 40 for task 2\n",
      "Image 39 from 40 for task 2\n",
      "Image 40 from 40 for task 2\n",
      "Evaluate task 3\n",
      "Image 1 from 10 for task 3\n",
      "Image 2 from 10 for task 3\n",
      "Image 3 from 10 for task 3\n",
      "Image 4 from 10 for task 3\n",
      "Image 5 from 10 for task 3\n",
      "Image 6 from 10 for task 3\n",
      "Image 7 from 10 for task 3\n",
      "Image 8 from 10 for task 3\n",
      "Image 9 from 10 for task 3\n",
      "Image 10 from 10 for task 3\n"
     ]
    }
   ],
   "source": [
    "evaluate_task1(train_or_test = 'train')\n",
    "evaluate_task2(train_or_test = 'train')\n",
    "evaluate_task3(train_or_test = 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
